import asyncio
from agents import Agent, Runner
from pydantic import BaseModel
from quiz_gen.type_annotations import QAPair, QuestionCreatingError
from typing import List
from quiz_gen.agent_utils.agent_prompts import Sam
from random import shuffle

class QMA(BaseModel):
    question: str
    correct_answer: str
    incorrect_answers: List[str]
    question_time: int

# Mal improves the questions, and adds additional incorrect answers. she outputs question, correct answer, and incorrect_answers.
mal_sys_prompt = (
    "You are Mal, an expert in educational content refinement and multiple choice question design. "
    "Your task is to first improve the given question based on the provided audience and objectives, "
    "and then generate a multiple choice question in JSON format. "
    "The output JSON must adhere to the following structure:\n"
    "  {\n"
    '    "question": <string>,\n'
    '    "correct_answer": <string>,\n'
    '    "incorrect_answers": <list of three strings>\n'
    '    "question_time": <number (seconds)>'
    "  }\n"
    "Ensure that the overall multiple choice question has exactly four options (one correct answer and three distractors). "
    "If it is not possible to create a valid multiple choice question from the input, output a JSON object ERROR, as the question value. "
    "Do not include any extraneous text or commentary outside of the JSON response."
)

mal = Agent(name="Mal", instructions=mal_sys_prompt, output_type=QMA)

async def call_mal(question: str, answer: str, title: str, audience_and_objectives: str):
    """Mal improves the questions, and adds additional incorrect answers. she outputs 

    Args:
        question (str): Question generated by Nandy
        answer (str): Answer generated by Nandy
        title (str): Quiz title (generated by Sam)
        audience_and_objectives (str): Sam provided info

    Returns:
        QMA(Basemodel): question, correct answer, and incorrect_answers.
    """
    mal_user_prompt = (
        f"Quiz Title: {title}\n"
        f"Audience and Objectives: {audience_and_objectives}\n"
        f"Original Question: {question}\n"
        f"Original Answer: {answer}\n\n"
        "Using the above details, please refine and improve the original question for clarity and relevance, "
        "then convert it into a multiple choice question in the following JSON format:\n"
        '{\n'
        '  "question": "<improved multiple choice question>",\n'
        '  "correct_answer": "<the correct answer>",\n'
        '  "incorrect_answers": ["<distractor1>", "<distractor2>", "<distractor3>"]\n'
        '  "question_time": <question time appearing on screen, usually around 20-30 seconds, answer only in seconds.>'
        '}\n'
        "Remember to create exactly four options. If you cannot generate the multiple choice question, reply with a JSON object "
        "with the key \"error\" followed by a brief explanation."
    )

    result = await Runner.run(mal, mal_user_prompt)
    question = result.final_output.question
    correct_answer = result.final_output.correct_answer
    incorrect_answers = result.final_output.incorrect_answers
    question_time = result.final_output.question_time

    return question, correct_answer, incorrect_answers, question_time

#Blip verifies that the question is clear, based on the audience. If it is, Blip responds with "GREAT", if not, tells Nan to create a new question.
blip_system_prompt = (
    "You are Blip, an expert in assessing the clarity and conciseness of educational content. "
    "Your task is to evaluate a multiple choice question within the context of its quiz. "
    "You will review the quiz title, the intended audience and objectives, the question, the correct answer, "
    "and the list of incorrect answers. Ensure that the question is clear, concise, and appropriate for the given audience, "
    "that the correct answer is unambiguous, and that the incorrect answers are plausible distractors that align with the context. "
    "If all aspects are acceptable, respond with exactly 'GREAT'. "
    "If any issue is found, respond with 'ERROR:' followed by a brief explanation (for example, 'question is confusing' or 'correct answer is not clear'). "
    "Do not include any extra commentary or text outside of this format."
)
blip = Agent(name="Blip", instructions=blip_system_prompt)

async def call_blip(title: str, audience_and_objectives: str, qa):
    """Blip is another layer of varification, it ensures that the answer will fit the audience, if not, the question will be regenerated using Nan.

    Args:
        title (str): Quiz title (generated by Sam)
        audience_and_objectives (str): info generated by Sam about the
        qa (_type_): Question and answers

    Returns:
        _type_: 'GREAT' if everything is acceptable, or 'ERROR'
    """
    user_prompt = (
        f"Quiz Title: {title}\n"
        f"Audience and Objectives: {audience_and_objectives}\n"
        f"Question: {qa[0]}\n"
        f"Correct Answer: {qa[1]}\n"
        f"Incorrect Answers: {qa[2]}\n\n"
        f"Question Time: {qa[3]}\n\n"
        "Please evaluate the above multiple choice question in its entirety. "
        "Determine if the question, the correct answer, and the incorrect answers are clear, concise, and appropriate "
        "for the intended audience and objectives. "
        "Return exactly 'GREAT' if everything is acceptable, or 'ERROR', followed by a brief explanation (for example, 'question is confusing' or 'correct answer is not clear')"
    )

    result = await Runner.run(blip, user_prompt)
    return result.final_output

# Nan creates a single new question, in case a question wasn't clear. he's a modified version of Nandy.
nan_sys_prompt = (
    "You are a question-making assistant. "
    "Your task is to generate a new quiz question–answer pair using the provided details. "
    "You will be given the following inputs: quiz title, study material summary, audience and objectives, additional info, "
    "and an expanded summary of the study material. "
    "Using these inputs, generate one new question and its correct answer. "
    "Output your result strictly in JSON format with the keys 'question' and 'answer'. "
    "Do not include any extra commentary or text."
)

nan = Agent(name="Nan", instructions=nan_sys_prompt, output_type=QAPair)

async def gen_question(info: Sam, expanded_summary: str):
    """Nan Generates a new question in case a question was removed by Blip

    Args:
        info (Sam): info Summarized by Sam
        expanded_summary (str): research summary by Roby

    Returns:
        _type_: new question
    """
    user_prompt = (
        f"Please generate a new question–answer pair using the following details:\n"
        f"- Quiz Title: {info.title}\n"
        f"- Study Material Summary: {info.study_material_summary}\n"
        f"- Audience and Objectives: {info.audience_and_objectives}\n"
        f"- Additional Info: {info.additional_info}\n"
        f"- Expanded Summary: {expanded_summary}\n\n"
        "Output your result as a JSON object in the following format:\n"
        '{\n'
        '  "question": "<your new question>",\n'
        '  "answer": "<your new answer>"\n'
        '}\n'
        "Do not include any extra text."
    )
    result = await Runner.run(nan, user_prompt)
    print(result.final_output)
    return result.final_output

max_retries = 5
async def iter_questions(questions: dict, info: Sam, expanded_summary: str):
    """iter_questions iterates on questions, improves them, verifies them and adds more answers using the agents."""
    new_questions = {}
    
    async def gen_new_question(question = None, answer = None, retries = 0) -> dict:
        if retries > max_retries:
            raise QuestionCreatingError("Maximum retries reached while generating a valid question")

        response = await call_mal(question, answer, info.title, info.audience_and_objectives)
        if "ERROR" in response[0]:
            question, answer = await gen_question(info, expanded_summary)
            return await gen_new_question(question, answer)
        else:
            verification = await call_blip(info.title, info.audience_and_objectives, response)
            if "GREAT" not in verification:
                print("creating new question! \n")
                question, answer = await gen_question(info, expanded_summary)
                return await gen_new_question(question, answer)
            else:
                return response
            
    async def iter_over_questions(q, a):
        question, correct_answers, incorrect_answers, question_time = await gen_new_question(q, a)
        answers = [{"info": {"duration": question_time}}]
        for i in incorrect_answers:
            answers.append({i: False})
        if isinstance(correct_answers, list):
            for i in correct_answers:
                answers.append({i: True})
        else:
            answers.append({correct_answers: True})
        
        # Shuffles the answers, but keeps the info as the first argument (for easier handling later)
        ans_lst = answers[1:]
        shuffle(ans_lst)
        answers[1:] = ans_lst

        new_questions.update({question: answers})
        

    async with asyncio.TaskGroup() as tg:
        for q, a in questions.items():
            tg.create_task(iter_over_questions(q, a))
    
    return new_questions